# -*- coding: utf-8 -*-
"""Final_HeartDisease Prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZdxUoFDsRiYC6zkt42HUqiHfe2lX_rVw
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import VotingClassifier, RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, roc_curve, confusion_matrix

data = pd.read_csv('heart.csv')
print("Dataset loaded successfully!")

data.shape

print(data.dtypes)

print(data.info())

print("\n--- Dataset Preview ---")
print(data.head())
print("\n--- Dataset Info ---")
print(data.info())
print("\n--- Summary Statistics ---")
print(data.describe())

print("\n--- Missing Values ---")
print(data.isnull().sum())

sns.countplot(x='target', data=data)
plt.title('Target Variable Distribution')
plt.xlabel('Heart Disease (1 = Yes, 0 = No)')
plt.ylabel('Count')
plt.show()

# Print counts
print(data['target'].value_counts())

fig, axes = plt.subplots(1, len(num_features), figsize=(20, 4))

for idx, col in enumerate(num_features):
    sns.histplot(data[col], kde=True, ax=axes[idx])
    axes[idx].set_title(f'{col}')

plt.tight_layout()
plt.show()

"""Age:

"The age distribution is slightly skewed toward middle-aged patients, with most individuals between 50 and 60 years old â€” a typical risk group for heart disease."

Trestbps (Resting Blood Pressure):

"Most patients have resting blood pressures between 120 and 140 mmHg, which is slightly above the ideal range, suggesting early hypertension risks."

Chol (Cholesterol):

"Cholesterol levels are right-skewed, with most patients between 200 and 300 mg/dl, but a few extreme outliers reaching above 400."

Thalach (Maximum Heart Rate Achieved):

"Maximum heart rates are roughly bell-shaped, centered around 150 bpm, indicating a normal distribution of heart fitness among patients."

Oldpeak (ST Depression):

"Oldpeak values are heavily skewed toward 0, meaning most patients show little or no ST depression, but a smaller group has significant depression linked to heart disease risk."
"""

plt.figure(figsize=(10, 8))
sns.heatmap(data.corr(), annot=True, cmap='coolwarm')
plt.title("Correlation Heatmap")
plt.show()

plt.figure(figsize=(14,8))
sns.boxplot(data)
plt.show()

cat_features = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'ca', 'thal']

# Set up figure: 2 rows Ã— 4 columns
fig, axes = plt.subplots(2, 4, figsize=(20, 10))

# Flatten axes for easy iteration
axes = axes.flatten()

# Plot each categorical feature
for idx, col in enumerate(cat_features):
    sns.countplot(x=col, hue='target', data=data, ax=axes[idx])
    axes[idx].set_title(f'{col} vs Target')
    axes[idx].legend(title='Heart Disease')

# Adjust layout
plt.tight_layout()
plt.show()

"""Sex vs Target:

Males are more frequent overall, but a larger proportion of females have heart disease compared to males.

cp (Chest Pain) vs Target:

Chest pain types 1 and 2 are highly associated with the presence of heart disease.

fbs (Fasting Blood Sugar) vs Target:

Fasting blood sugar levels do not show a strong difference between those with and without heart disease.

restecg (Resting ECG) vs Target:

Most individuals have a normal ECG (restecg=0), with slight variations in heart disease occurrence across types.

exang (Exercise-Induced Angina) vs Target:

Absence of exercise-induced angina (exang=0) is more common among people with heart disease.

slope (Slope of ST Segment) vs Target:

A downsloping ST segment (slope=2) is strongly associated with heart disease.

ca (Number of Major Vessels) vs Target:

Having no major vessels colored (ca=0) is linked to a higher incidence of heart disease.

thal (Thalassemia Test Result) vs Target:

A reversible defect (thal=2) is strongly related to the presence of heart disease.
"""

# Step 5: Define features (X) and target (y)
X = data.drop('target', axis=1)  # Features
y = data['target']              # Target variable

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
print("\n--- Dataset Split ---")
print(f"Training set: {X_train.shape}, Testing set: {X_test.shape}")

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

print("\n--- Model Training and Evaluation ---")

lr = LogisticRegression(max_iter=1000)
lr.fit(X_train_scaled, y_train)
lr_pred = lr.predict(X_test_scaled)
lr_acc = accuracy_score(y_test, lr_pred)
print(f"Logistic Regression Accuracy: {lr_acc:.4f}")

rf = RandomForestClassifier(random_state=42)
rf.fit(X_train, y_train)
rf_pred = rf.predict(X_test)
rf_acc = accuracy_score(y_test, rf_pred)
print(f"Random Forest Accuracy: {rf_acc:.4f}")

svm = SVC(probability=True)
svm.fit(X_train_scaled, y_train)
svm_pred = svm.predict(X_test_scaled)
svm_acc = accuracy_score(y_test, svm_pred)
print(f"SVM Accuracy: {svm_acc:.4f}")

from sklearn.neighbors import KNeighborsClassifier

models = {
    'Logistic Regression': LogisticRegression(max_iter=1000),
    'Random Forest': RandomForestClassifier(),
    'K-Nearest Neighbors': KNeighborsClassifier(),
    'SVM': SVC()
}

for name, model in models.items():
    model.fit(X_train_scaled, y_train)
    y_pred = model.predict(X_test_scaled)

    print(f"\nðŸ“Œ {name}")
    print("Accuracy:", accuracy_score(y_test, y_pred))
    print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))
    print("Classification Report:\n", classification_report(y_test, y_pred))

from sklearn.model_selection import cross_val_score
import numpy as np

# Models dictionary (reuse scaled features from before)
models = {
    'Logistic Regression': LogisticRegression(max_iter=1000),
    'Random Forest': RandomForestClassifier(),
    'K-Nearest Neighbors': KNeighborsClassifier(),
    'SVM': SVC()
}

print("ðŸ“Š 5-Fold Cross-Validation Results:\n")
for name, model in models.items():
    scores = cross_val_score(model, X_train_scaled, y_train, cv=5, scoring='accuracy')
    print(f"{name}:")
    print(f"  Mean Accuracy: {scores.mean():.4f}")
    print(f"  Standard Deviation: {scores.std():.4f}")
    print(f"  All Fold Scores: {scores}\n")

import pandas as pd

results = {
    'Model': [],
    'Mean Accuracy': [],
    'Std Dev': [],
    'Fold Scores': []
}

for name, model in models.items():
    scores = cross_val_score(model, X_train_scaled, y_train, cv=5, scoring='accuracy')
    results['Model'].append(name)
    results['Mean Accuracy'].append(scores.mean())
    results['Std Dev'].append(scores.std())
    results['Fold Scores'].append(scores)

results_df = pd.DataFrame(results)
print(results_df)

import seaborn as sns
import matplotlib.pyplot as plt

plt.figure(figsize=(10,6))
sns.barplot(x='Mean Accuracy', y='Model', data=results_df.sort_values('Mean Accuracy', ascending=False), palette='viridis')
plt.title('Model Comparison (5-Fold CV Accuracy)')
plt.xlabel('Mean Accuracy')
plt.ylabel('Model')
plt.xlim(0.8, 1.0)
plt.show()

voting_model = VotingClassifier(
    estimators=[
        ('lr', lr),
        ('rf', rf),
        ('svm', svm)
    ],
    voting='soft'  # Use soft voting for probability-based predictions
)
voting_model.fit(X_train_scaled, y_train)

voting_pred = voting_model.predict(X_test_scaled)
voting_acc = accuracy_score(y_test, voting_pred)
print(f"\nVoting Classifier Accuracy: {voting_acc:.4f}")

voting_cm = confusion_matrix(y_test, voting_pred)
print("\n--- Confusion Matrix ---")
print(voting_cm)

voting_report = classification_report(y_test, voting_pred)
print("\n--- Classification Report ---")
print(voting_report)

voting_prob = voting_model.predict_proba(X_test_scaled)[:, 1]
voting_auc = roc_auc_score(y_test, voting_prob)
print(f"Voting Classifier ROC-AUC Score: {voting_auc:.4f}")

fpr, tpr, _ = roc_curve(y_test, voting_prob)
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, label=f"Voting Classifier (AUC = {voting_auc:.4f})")
plt.plot([0, 1], [0, 1], 'k--', label="Random Guessing")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve")
plt.legend()
plt.show()

import joblib
joblib.dump(voting_model, 'voting_classifier.pkl')
joblib.dump(scaler, 'scaler.pkl')
print("\nTrained model and scaler saved as 'voting_classifier.pkl' and 'scaler.pkl'!")

from google.colab import files

# Download the files
files.download('voting_classifier.pkl')
files.download('scaler.pkl')
